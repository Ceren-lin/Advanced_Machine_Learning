{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-05T15:08:05.559318300Z",
     "start_time": "2024-04-05T15:08:05.554559400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaaaaaa', 'aaaaaad', 'aaaaadd', 'aaaaada', 'aaaadda', 'aaaaddd', 'aaaadad', 'aaaadaa', 'aaaddaa', 'aaaddad', 'aaadddd', 'aaaddda', 'aaadada', 'aaadadd', 'aaadaad', 'aaadaaa', 'aaddaaa', 'aaddaad', 'aaddadd', 'aaddada', 'aadddda', 'aaddddd', 'aadddad', 'aadddaa', 'aadadaa', 'aadadad', 'aadaddd', 'aadadda', 'aadaada', 'aadaadd', 'aadaaad', 'aadaaaa', 'addaaaa', 'addaaad', 'addaadd', 'addaada', 'addadda', 'addaddd', 'addadad', 'addadaa', 'addddaa', 'addddad', 'adddddd', 'addddda', 'adddada', 'adddadd', 'adddaad', 'adddaaa', 'adadaaa', 'adadaad', 'adadadd', 'adadada', 'adaddda', 'adadddd', 'adaddad', 'adaddaa', 'adaadaa', 'adaadad', 'adaaddd', 'adaadda', 'adaaada', 'adaaadd', 'adaaaad', 'adaaaaa', 'ddaaaaa', 'ddaaaad', 'ddaaadd', 'ddaaada', 'ddaadda', 'ddaaddd', 'ddaadad', 'ddaadaa', 'ddaddaa', 'ddaddad', 'ddadddd', 'ddaddda', 'ddadada', 'ddadadd', 'ddadaad', 'ddadaaa', 'ddddaaa', 'ddddaad', 'ddddadd', 'ddddada', 'dddddda', 'ddddddd', 'dddddad', 'dddddaa', 'dddadaa', 'dddadad', 'dddaddd', 'dddadda', 'dddaada', 'dddaadd', 'dddaaad', 'dddaaaa', 'dadaaaa', 'dadaaad', 'dadaadd', 'dadaada', 'dadadda', 'dadaddd', 'dadadad', 'dadadaa', 'dadddaa', 'dadddad', 'daddddd', 'dadddda', 'daddada', 'daddadd', 'daddaad', 'daddaaa', 'daadaaa', 'daadaad', 'daadadd', 'daadada', 'daaddda', 'daadddd', 'daaddad', 'daaddaa', 'daaadaa', 'daaadad', 'daaaddd', 'daaadda', 'daaaada', 'daaaadd', 'daaaaad', 'daaaaaa']\n",
      "['1.0922557125948564', '0.9588106826522127', '17.035515208876593', '17.583847101892786', '37.59948111362533', '38.43230312410685', '0.9268472154034573', '1.0614950880601568', '39.20477182286458', '38.76161695874558', '4.164024063098418', '4.020518246650791', '7.006462805555675', '7.193306485697574', '2.4876010129331756', '2.378177212542792', '0.6638272729320286', '0.6486638536231422', '0.5636064719468118', '0.5496548234238743', '0.8592203924171468', '0.8792585746739634', '0.7390293841322406', '0.7576372617192565', '7.1954945297851785', '7.1577990976724974', '3.679851208330619', '3.652894492727636', '2.327298859651276', '2.3508200353921156', '0.574785472937338', '0.5864988010570278', '0.052710256907463456', '0.056674034197956684', '0.039546561792882996', '0.04298451138037119', '0.019157605975071077', '0.016683323975778704', '0.012035467128235765', '0.010089647037613579', '0.134114871559613', '0.12502316355543738', '0.007651082538415156', '0.010017256529995647', '0.04632376146961373', '0.04142706286928313', '0.4447526114830147', '0.42927323722457755', '0.006336932874002948', '0.005193098166310354', '0.008826562791601055', '0.007467848242927401', '0.032312308825834135', '0.035408191046599743', '0.036840276855184824', '0.04014459373214107', '1.2344461557614794', '1.2333298758168205', '0.30203993772638277', '0.30148197634849944', '0.2915075450753079', '0.2925949157645518', '0.0005627952846113937', '0.0005163222633236264', '0.002029880959002254', '0.0018074641838562485', '0.017665972069663142', '0.018346525206980505', '0.0020951338409239454', '0.002360789653988622', '0.017662676996184717', '0.01692125563039096', '0.12438184603655318', '0.12171796333260268', '0.003098422029707841', '0.002690607282989339', '0.07298966499505166', '0.07488054440085533', '0.0006834357180370067', '0.0005135117672297868', '0.05568047897321363', '0.05715902335858746', '0.003535047893945905', '0.003914309766047552', '0.05004362423021316', '0.048557452749467954', '0.002285349076807506', '0.001976187786663736', '0.009751904674494369', '0.009178030543854819', '0.13895975291874677', '0.1367720260715317', '0.014577073341620105', '0.015238677408563344', '0.15631642804795481', '0.15846918880138766', '0.0004974371659672391', '0.0003045367602227103', '0.00890414247374768', '0.009842264886735435', '0.0017937748714063617', '0.0022693107072962247', '0.005683977063489181', '0.004914289900903545', '0.021327526298042795', '0.01943828940522484', '0.037937879731393905', '0.040556860712239906', '0.014596656506957486', '0.013160481631732003', '0.21210861187374908', '0.20652265772135367', '0.0033181537349373682', '0.0028374638009516233', '0.03235589718248388', '0.030816465095498253', '0.008964882361281033', '0.009901808936591304', '0.04655800742903887', '0.04866528145262981', '0.49584337155794167', '0.49605947478187407', '0.10337522560468014', '0.10347214517263344', '0.1637757633266188', '0.16388712862038368', '0.0004354252668264398', '0.00044106862346093454']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "# 使用 with 语句打开 CSV 文件\n",
    "with open(\"E:\\毕设\\电路仿真\\仿真结果\\sallen_key\\小波包分解1\\C1-//1_0_features.csv\", mode='r', encoding='utf-8') as file:\n",
    "    # 创建一个 csv reader 对象\n",
    "    csv_reader = csv.reader(file)\n",
    "    \n",
    "    # next(csv_reader, None)  # 如果需要跳过标题行\n",
    "    \n",
    "    # 遍历 csv_reader 读取每行数据\n",
    "    for row in csv_reader:\n",
    "        print(row)  # row 是一个列表，包含了当前行的所有数据\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 32, 32, 32, 32, 32, 31, 31, 31, 31, 30, 29, 28, 26, 24, 21, 16, 9, 2, 2, 2, 3, 4, 5, 7, 11, 16, 17, 21, 27, 33, 45, 56, 56, 56, 56, 56, 56, 56, 54, 49, 40, 30, 24, 21, 22, 25, 29, 33, 35, 37, 37, 35, 34, 32, 31, 30, 30, 30, 31, 32, 33, 33, 33, 33, 33, 32, 32, 32, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv(\"E:\\毕设\\电路仿真\\仿真结果\\\\four_op_amp\\原始数据文件//NF//0_0.csv\", names=['Time', 'V(OUT)@1'])\n",
    "\n",
    "# 转换数据类型\n",
    "data['Time'] = pd.to_numeric(data['Time'], errors='coerce')\n",
    "data['V(OUT)@1'] = pd.to_numeric(data['V(OUT)@1'], errors='coerce')\n",
    "\n",
    "# 过滤出非零波形部分\n",
    "filtered_data = data[data['V(OUT)@1'] != 0.0]\n",
    "\n",
    "v_out_list = data['V(OUT)@1'].tolist()\n",
    "#print(v_out_list)\n",
    "\n",
    "squared_list = [x*(10**2) for x in v_out_list] \n",
    "#print(squared_list)\n",
    "\n",
    "rounded_list = [round(x) for x in squared_list if not math.isnan(x)]\n",
    "#print(rounded_list)\n",
    "\n",
    "list_1 = [round(x/15+32) for x in rounded_list if not math.isnan(x)] \n",
    "print(list_1)\n",
    "# 可以进行的处理示例：计算波形的平均值和标准偏差\n",
    "# mean = filtered_data['V(OUT)@1'].mean()\n",
    "# std = filtered_data['V(OUT)@1'].std()\n",
    "# \n",
    "# print('Waveform Mean:', mean)\n",
    "# print('Waveform Standard Deviation:', std)\n",
    "\n",
    "# 更多的数据处理可以在这里添加\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T15:09:02.739447200Z",
     "start_time": "2024-04-05T15:09:02.735968900Z"
    }
   },
   "id": "ec4583c7f115a1cd",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data_list = []\n",
    "\n",
    "# 使用 with 语句打开 CSV 文件\n",
    "with open('E:\\毕设\\电路仿真\\仿真结果\\切比雪夫电路lm358\\切比雪夫滤波电路LM358.csv', mode='r', encoding='utf-8') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        data_dict = {}\n",
    "        # 处理每一行，提取电阻和电容的值\n",
    "        for cell in row:\n",
    "            if 'resistance' in cell:\n",
    "                # 提取电阻值\n",
    "                data_dict['resistance'] = float(cell.split('=')[1])\n",
    "            elif 'capacitance' in cell:\n",
    "                # 提取电容值\n",
    "                data_dict['capacitance'] = float(cell.split('=')[1])\n",
    "        # 如果字典不为空，则添加到列表中\n",
    "        if data_dict:\n",
    "            data_list.append(data_dict)\n",
    "\n",
    "# 打印或进一步处理data_list\n",
    "print(data_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-05T15:07:39.060367500Z"
    }
   },
   "id": "5bed3cd9b3562ea0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 将从OrCAD Pspice文件中读出来的数据整理后存储\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 加载CSV文件\n",
    "file_path = \"C://Users\\Ceren\\Desktop//t0.csv\"  # 请替换'你的文件路径'为实际的文件路径\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 去除列名的前后空格\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# 定义保存新文件的基础路径\n",
    "base_file_path = 'E:\\毕设\\电路仿真\\仿真结果\\sallen_key\\原始数据文件//NF/0_'  # 请替换'你的保存路径'为实际希望保存文件的路径\n",
    "\n",
    "ii=0\n",
    "\n",
    "# 遍历除了'Time'列之外的所有列，并将数据保存到新文件中\n",
    "for column in df.columns[1:]:  # 跳过'Time'列\n",
    "    # 定义当前列的新文件路径\n",
    "    new_file_path = f'{base_file_path}{ii}.csv'\n",
    "    ii=ii+1\n",
    "    # 提取当前列以及'Time'列的数据\n",
    "    data_to_save = df[['Time', column]].copy()\n",
    "    \n",
    "    # 将数据保存到CSV文件\n",
    "    data_to_save.to_csv(new_file_path, index=False)\n",
    "\n",
    "print(\"数据已成功保存到指定文件中。\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-05T15:07:39.060367500Z"
    }
   },
   "id": "ddbd7a1b1b428eb1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pywt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "file_path = '你的文件路径/test.csv'  # 替换为你的文件路径\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 去除列名的前后空格，并选择一个列进行分析\n",
    "df.columns = df.columns.str.strip()\n",
    "signal = df['(V(OUT))@1'].values  # 以(V(OUT))@1为例\n",
    "\n",
    "# 定义小波包分析的参数\n",
    "wavelet = 'db1'  # 小波基，可以根据需要选择不同的小波基\n",
    "max_level = pywt.dwt_max_level(data_len=len(signal), filter_len=pywt.Wavelet(wavelet).dec_len)\n",
    "\n",
    "# 执行小波包分解\n",
    "wp = pywt.WaveletPacket(data=signal, wavelet=wavelet, mode='symmetric', maxlevel=max_level)\n",
    "\n",
    "# 遍历小波包树，并提取各节点的系数\n",
    "coefficients = {}\n",
    "for node in wp.get_level(max_level, 'freq'):\n",
    "    coefficients[node.path] = node.data\n",
    "\n",
    "# 可选：分析、可视化或进一步处理小波包系数\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-05T15:07:39.061361100Z"
    }
   },
   "id": "a12d884aaaf77ae5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pywt\n",
    "\n",
    "# 重新加载文件，这次确保跳过列名\n",
    "file_path = \"E:\\毕设\\电路仿真\\仿真结果\\sallen_key\\原始数据文件\\C1-//1_0.csv\"\n",
    "df = pd.read_csv(file_path, header=None, skiprows=1)\n",
    "\n",
    "# 假设信号在第二列\n",
    "signal = df.iloc[:, 1].values\n",
    "\n",
    "# 定义小波包分析参数\n",
    "wavelet = 'db1'  # 选择合适的小波基\n",
    "max_level = pywt.dwt_max_level(data_len=len(signal), filter_len=pywt.Wavelet(wavelet).dec_len)\n",
    "\n",
    "# 执行小波包分解\n",
    "wp = pywt.WaveletPacket(data=signal, wavelet=wavelet, mode='symmetric', maxlevel=max_level)\n",
    "\n",
    "# 提取并遍历小波包系数\n",
    "coefficients = {}\n",
    "for node in wp.get_level(max_level, 'freq'):\n",
    "    coefficients[node.path] = node.data\n",
    "\n",
    "# 输出系数的数量和一些节点的路径作为验证\n",
    "len(coefficients), list(coefficients.keys())[:5]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T15:07:39.063940400Z",
     "start_time": "2024-04-05T15:07:39.062361300Z"
    }
   },
   "id": "533894b44c22c5f6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 定义提取能量特征的函数\n",
    "def extract_features(coefficients):\n",
    "    features = {}\n",
    "    for path, data in coefficients.items():\n",
    "        energy = sum(data**2)\n",
    "        features[path] = energy\n",
    "    return features\n",
    "\n",
    "# 使用之前小波包分解得到的系数\n",
    "features = extract_features(coefficients)\n",
    "\n",
    "# 打印一些特征进行验证\n",
    "list(features.items())[:10]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-05T15:07:39.062896100Z"
    }
   },
   "id": "82d7dec8e9a3110c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 确保使用正确的数值数据重新进行小波包分解\n",
    "# 重新加载数据，确保跳过标题，并且正确转换数值\n",
    "df = pd.read_csv(file_path, header=None, skiprows=1)\n",
    "signal_corrected = df.iloc[:, 1].astype(float).values  # 确保转换为浮点数\n",
    "\n",
    "# 使用修正后的信号重新执行小波包分解\n",
    "wp_corrected = pywt.WaveletPacket(data=signal_corrected, wavelet=wavelet, mode='symmetric', maxlevel=max_level)\n",
    "\n",
    "# 使用修正后的小波包对象进行信号重构\n",
    "reconstructed_signal_corrected = wp_corrected.reconstruct(update=True)\n",
    "\n",
    "# 比较原始信号和重构信号的前几个值\n",
    "original_signal_first_values_corrected = signal_corrected[:10]\n",
    "reconstructed_signal_first_values_corrected = reconstructed_signal_corrected[:10]\n",
    "\n",
    "original_signal_first_values_corrected, reconstructed_signal_first_values_corrected\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-05T15:07:39.063940400Z"
    }
   },
   "id": "39c213effc93a651",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pywt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def process_and_save_features(file_path, output_dir, wavelet='db1', max_level=None):\n",
    "    # 读取数据，跳过第一行（列名）\n",
    "    df = pd.read_csv(file_path, header=None, skiprows=1)\n",
    "    \n",
    "    # 将第二列转换为浮点数，用作信号\n",
    "    signal = df.iloc[:, 1].astype(float).values\n",
    "    \n",
    "    # 执行小波包分析\n",
    "    wp = pywt.WaveletPacket(data=signal, wavelet=wavelet, mode='symmetric', maxlevel=max_level)\n",
    "    \n",
    "    # 提取特征：这里我们简单地使用每个节点的能量作为特征\n",
    "    features = {node.path: np.sum(node.data**2) for node in wp.get_level(max_level or wp.maxlevel, 'freq')}\n",
    "    \n",
    "    # 将特征保存到DataFrame中\n",
    "    features_df = pd.DataFrame([features])\n",
    "    \n",
    "    # 确保输出目录存在\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # 构建输出文件路径\n",
    "    output_file_path = os.path.join(output_dir, os.path.basename(file_path).replace('.csv', '_features.csv'))\n",
    "    \n",
    "    # 将特征保存到CSV文件中\n",
    "    features_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# 示例：处理一个文件\n",
    "file_path = \"E:\\毕设\\电路仿真\\仿真结果\\sallen_key\\原始数据文件\\C1-//1_0.csv\"  # 请替换为您的文件路径\n",
    "output_dir = \"E:\\毕设\\电路仿真\\仿真结果\\sallen_key\\小波包分解1\\C1-\"  # 请替换为您希望保存特征文件的目录路径\n",
    "process_and_save_features(file_path, output_dir)\n",
    "\n",
    "# 如果您有多个文件，您可以遍历文件路径列表，并为每个文件调用`process_and_save_features`函数\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T15:07:39.066936Z",
     "start_time": "2024-04-05T15:07:39.063940400Z"
    }
   },
   "id": "e4c4e7f31195b67f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pywt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def process_and_save_features(file_path, output_dir, wavelet='db1', max_level=None):\n",
    "    # 读取数据，跳过第一行（列名）\n",
    "    df = pd.read_csv(file_path, header=None, skiprows=1)\n",
    "    \n",
    "    # 将第二列转换为浮点数，用作信号\n",
    "    signal = df.iloc[:, 1].astype(float).values\n",
    "    \n",
    "    # 执行小波包分析\n",
    "    wp = pywt.WaveletPacket(data=signal, wavelet=wavelet, mode='symmetric', maxlevel=max_level)\n",
    "    \n",
    "    # 提取特征：这里我们简单地使用每个节点的能量作为特征\n",
    "    features = {node.path: np.sum(node.data**2) for node in wp.get_level(max_level or wp.maxlevel, 'freq')}\n",
    "    \n",
    "    # 将特征保存到DataFrame中\n",
    "    features_df = pd.DataFrame([features])\n",
    "    \n",
    "    # 确保输出目录存在\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # 构建输出文件路径\n",
    "    output_file_path = os.path.join(output_dir, os.path.basename(file_path).replace('.csv', '_features.csv'))\n",
    "    \n",
    "    # 将特征保存到CSV文件中\n",
    "    features_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "def process_all_files_in_directory(directory_path, output_dir, wavelet='db1', max_level=None):\n",
    "    # 构建目录路径中所有CSV文件的搜索模式\n",
    "    search_pattern = os.path.join(directory_path, \"*.csv\")\n",
    "    \n",
    "    # 使用glob找到所有匹配的文件\n",
    "    csv_files = glob.glob(search_pattern)\n",
    "    \n",
    "    # 遍历所有找到的CSV文件\n",
    "    for file_path in csv_files:\n",
    "        # 对每个文件执行小波包分析并保存特征\n",
    "        process_and_save_features(file_path, output_dir, wavelet, max_level)\n",
    "\n",
    "# 设置源文件目录和目标目录路径\n",
    "directory_path = \"E:/毕设/电路仿真/仿真结果/sallen_key/原始数据文件/NF/\"  # 源文件目录路径\n",
    "output_dir = \"E:/毕设/电路仿真/仿真结果/sallen_key/小波包分解1/NF/\"  # 输出目录路径\n",
    "\n",
    "# 处理目录下的所有文件\n",
    "process_all_files_in_directory(directory_path, output_dir)\n",
    "\n",
    "print('数据处理完成')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-05T15:07:39.064931800Z"
    }
   },
   "id": "6ad955373e723156",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 假设你的CSV文件路径\n",
    "csv_file_path = 'your_data.csv'\n",
    "\n",
    "# 读取数据\n",
    "# 假设最后一列是标签\n",
    "data = pd.read_csv(csv_file_path)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# 数据预处理\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 将数据转换为PyTorch张量\n",
    "X = torch.Tensor(X)\n",
    "y = torch.Tensor(y).long()  # 假设y是整数类别标签\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定义PyTorch数据集\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "test_dataset = MyDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 定义1D-CNN模型\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 5, 128)  # Adjust the input size\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 实例化模型，定义损失函数和优化器\n",
    "num_classes = len(np.unique(y))\n",
    "model = CNN1D(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 评估模型\n",
    "model.eval()  # 设置模型\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-05T15:07:39.066936Z"
    }
   },
   "id": "1299e8a06e73dbf2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# 假设 X 和 y 是你的特征和标签数据，且已经准备好\n",
    "# 将它们转换为PyTorch张量\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)  # 对于分类问题，确保标签是长整型\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.2, random_state=42)\n",
    "\n",
    "# 再次转换为PyTorch张量\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# 创建TensorDataset和DataLoader\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# 定义1D-CNN模型\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=X_train.shape[1], out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Dropout(0.5))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * ((X_train.shape[2] - 2) // 2), 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 实例化模型、定义损失函数和优化器\n",
    "model = CNN1D(num_classes=y_train.unique().numel())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 测试模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the model on the test set: {100 * correct / total}%')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-05T15:07:39.066936Z"
    }
   },
   "id": "dcce0c1ddc89cf00"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 假设df是包含你数据集特征和标签的Pandas DataFrame\n",
    "# 例如，df = pd.read_csv('your_dataset.csv')\n",
    "df = pd.read_csv(\"E:\\毕设\\电路仿真\\仿真结果\\sallen_key\\小波包分解1\\C1-//1_0_features.csv\")\n",
    "\n",
    "# 绘制单个特征的分布图\n",
    "def plot_feature_distribution(df, feature_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[feature_name], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {feature_name}')\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.ylabel('Density')\n",
    "    plt.show()\n",
    "\n",
    "# 绘制特征之间的相关性热图\n",
    "def plot_correlation_heatmap(df):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_matrix = df.corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=2)\n",
    "    plt.title('Correlation Heatmap')\n",
    "    plt.show()\n",
    "\n",
    "# 示例：绘制特征'aaaaaaa'的分布图\n",
    "plot_feature_distribution(df, 'aaaaaaa')\n",
    "\n",
    "# 绘制特征之间的相关性热图\n",
    "plot_correlation_heatmap(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T15:07:39.067918300Z",
     "start_time": "2024-04-05T15:07:39.067918300Z"
    }
   },
   "id": "75f8b442b211f911",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from dataset import CustomDataset\n",
    "\n",
    "root_dir = \"E:\\\\毕设\\\\电路仿真\\\\仿真结果\\\\sallen_key\\\\小波包分解1\"  # 更新为你的路径\n",
    "dataset = CustomDataset(root_dir=root_dir)\n",
    "\n",
    "# 假设 dataset 是你的 CustomDataset 实例\n",
    "# 提取特征和标签\n",
    "features = np.array([sample[0].numpy() for sample in dataset])  # 根据你的数据结构调整\n",
    "labels = np.array([sample[1].numpy() for sample in dataset])  # 根据你的数据结构调整\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 应用 t-SNE 进行降维\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "features_tsne = tsne.fit_transform(features_scaled)\n",
    "\n",
    "# 可视化\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in np.unique(labels):\n",
    "    plt.scatter(features_tsne[labels == i, 0], features_tsne[labels == i, 1], label=f'Class {i}')\n",
    "plt.legend()\n",
    "plt.title('Features distribution with t-SNE')\n",
    "plt.xlabel('t-SNE feature 1')\n",
    "plt.ylabel('t-SNE feature 2')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T15:07:39.068910500Z",
     "start_time": "2024-04-05T15:07:39.067918300Z"
    }
   },
   "id": "a814e11a4eee0d9a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "print(pywt.wavelist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-05T15:07:39.068910500Z"
    }
   },
   "id": "a88e769fdae3418a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T15:07:39.075527400Z",
     "start_time": "2024-04-05T15:07:39.069923Z"
    }
   },
   "id": "bb6cf4d9e1f3f0c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
